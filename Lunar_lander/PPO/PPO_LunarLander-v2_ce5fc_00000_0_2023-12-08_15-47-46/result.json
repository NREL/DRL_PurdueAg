{"episode_reward_max": 48.29694930666224, "episode_reward_min": -569.8226626750653, "episode_reward_mean": -190.95234088757599, "episode_len_mean": 91.3953488372093, "episode_media": {}, "episodes_this_iter": 86, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-73.07901778613856, -361.53164429478926, -200.0313216882131, -165.00850876356546, -171.74458199372455, -452.71328064203016, -110.52836968684868, -433.30471244801123, -285.7688958893547, -122.29719495400639, -110.05389472136203, -285.7627655085688, -58.29947452441016, -107.2839763369231, -295.2413621371847, -110.81566672503428, -234.46007736480385, -102.12942883750671, -121.78062467414574, -110.4054712643476, -126.62740827721892, -294.30643516831617, -255.4065620962872, -36.57568447244621, -133.25416500014921, -160.0439207553022, -129.4780154028921, -113.84012302328196, -148.54209139551506, -159.85388702363588, -204.8720172112309, -94.09834045122766, -212.8151738331889, -298.8001456618399, -108.1730296649784, -208.5452974403884, -43.886755704199956, -134.35117173549355, -286.4272719388822, -569.8226626750653, -367.0655344598306, -202.58427623945795, -123.08576025472229, -143.61296134403767, -211.66238330071027, -71.76200661130476, -383.5671629207559, -204.60757609169482, -202.4898291770657, -118.01571283872993, -100.99133602498054, -159.3138745311697, -194.65814202176767, -97.49602407046496, -143.5416756878375, -367.0114162708711, -121.5664915973064, -146.94318315420713, -105.36178352423146, -114.99574139343159, -118.34346558909141, -88.91574346007607, -222.59803090963047, -108.51840322043299, -140.79362765194725, -131.77224915851684, -11.319659475267073, -301.3345991595053, -109.90878487081633, -202.56222403695295, -384.6705723578867, -73.46931628474941, -101.89287350145965, -229.05303477425446, -243.91450119461194, -466.9858115004417, -253.98090265611955, -474.06490216845793, -313.53638256332283, -212.1295804468054, -249.92157822284366, -217.09276363239292, 48.29694930666224, -334.1974107636107, -204.0844601743811, -62.844087177537304], "episode_lengths": [78, 70, 116, 113, 102, 88, 108, 113, 74, 64, 72, 96, 123, 76, 113, 90, 83, 73, 82, 64, 101, 97, 111, 94, 116, 96, 98, 81, 78, 75, 107, 63, 95, 109, 89, 81, 98, 96, 110, 109, 74, 78, 70, 61, 101, 100, 110, 73, 86, 89, 62, 68, 63, 102, 109, 91, 94, 85, 89, 83, 85, 85, 74, 67, 82, 128, 112, 104, 97, 64, 130, 76, 63, 98, 107, 123, 115, 111, 97, 79, 63, 100, 78, 132, 69, 131]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.043081246197736636, "mean_inference_ms": 0.28655753571974213, "mean_action_processing_ms": 0.027518128909260225, "mean_env_wait_ms": 0.11759946674781309, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 7998, "timesteps_this_iter": 7998, "agent_timesteps_total": 7998, "timers": {"sample_time_ms": 1373.703, "sample_throughput": 5822.219, "load_time_ms": 0.102, "load_throughput": 78378606.056, "learn_time_ms": 3786.829, "learn_throughput": 2112.057, "update_time_ms": 1.316}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 4.999999873689376e-05, "total_loss": 12469.8505859375, "policy_loss": -0.004512057639658451, "vf_loss": 12469.8525390625, "vf_explained_var": -0.003165526082739234, "kl": 0.015920374542474747, "entropy": 1.3701701164245605, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 7998, "num_agent_steps_sampled": 7998, "num_steps_trained": 7998, "num_steps_trained_this_iter": 7998, "num_agent_steps_trained": 7998}, "done": true, "episodes_total": 86, "training_iteration": 1, "trial_id": "ce5fc_00000", "experiment_id": "09d6466c63f9469aa4197f7b35ed6987", "date": "2023-12-08_15-48-03", "timestamp": 1702075683, "time_this_iter_s": 5.161106824874878, "time_total_s": 5.161106824874878, "pid": 58537, "hostname": "sakhtar-38586s", "node_ip": "127.0.0.1", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 1333, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "LunarLander-v2", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 1333, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "LunarLander-v2", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Box([-inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf], (8,), float32)", "Discrete(4)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 0, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Box([-inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf], (8,), float32)", "Discrete(4)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 0, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 5.161106824874878, "timesteps_since_restore": 7998, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 44.05, "ram_util_percent": 69.44999999999999}}
